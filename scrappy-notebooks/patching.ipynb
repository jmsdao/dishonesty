{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy snippet to get repo root from anywhere in the repo\n",
    "import sys\n",
    "from subprocess import check_output\n",
    "ROOT = check_output('git rev-parse --show-toplevel', shell=True).decode(\"utf-8\").strip()\n",
    "if ROOT not in sys.path: sys.path.append(ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import einops\n",
    "\n",
    "from functools import partial\n",
    "from dishonesty.mistral_lens import load_model\n",
    "from dishonesty.prompts import PROMPTS\n",
    "from dishonesty.utils import ntensor_to_long, calc_soft_kl_div\n",
    "\n",
    "\n",
    "t.set_grad_enabled(False)\n",
    "device = t.device('cuda:0' if t.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c733e7d5a0234b63a3b879d6882e5ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4096])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directions = t.load(f\"{ROOT}/directions/honesty_mistral-instruct-v0.1.pt\").to(device)\n",
    "directions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define injection hook\n",
    "def inject(module, input, output, alpha=-8.25):\n",
    "    new_output = [o for o in output]\n",
    "    new_output[0] += alpha * directions[15]\n",
    "    return tuple(new_output)\n",
    "\n",
    "\n",
    "# Syntactic sugar for injection\n",
    "def make_dishonest(model, alpha=-8.25):\n",
    "    model.add_hook(\"resid_post_15\", partial(inject, alpha=alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define activations to cache\n",
    "cache_names = []\n",
    "for i in range(14, 32):\n",
    "    cache_names.append(f\"resid_post_{i}\")\n",
    "    cache_names.append(f\"attn_out_{i}\")\n",
    "    cache_names.append(f\"head_out_{i}\")\n",
    "    cache_names.append(f\"mlp_out_{i}\")\n",
    "\n",
    "# Get dishonest logits and cache\n",
    "model.reset_hooks()\n",
    "make_dishonest(model)\n",
    "dishonest_logits, dishonest_cache = model.run_with_cache(PROMPTS, cache_names)\n",
    "\n",
    "# Get honest logits and cache\n",
    "model.reset_hooks()\n",
    "honest_logits, honest_cache = model.run_with_cache(PROMPTS, cache_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dishonest_cache.size()\n",
    "honest_cache.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to obtain patching metric\n",
    "def skld_recovery(patched_logits, temperature=1.0):\n",
    "    old_skld = calc_soft_kl_div(dishonest_logits, honest_logits, temperature=temperature)\n",
    "    new_skld = calc_soft_kl_div(dishonest_logits, patched_logits, temperature=temperature)\n",
    "    return 1 - (new_skld / old_skld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_hook(\n",
    "    module,\n",
    "    input,\n",
    "    output,\n",
    "    original_cache=None,\n",
    "    patching_cache=None,\n",
    "    cache_name=None,\n",
    "    pos_indexer=slice(None),\n",
    "    head_indexer=None,\n",
    "):\n",
    "    if patching_cache is None:\n",
    "        raise ValueError(\"patching_cache must be provided\")\n",
    "    if cache_name is None:\n",
    "        raise ValueError(\"cache_name must be provided\")\n",
    "\n",
    "    # Hook point should be `mlp_out_i`\n",
    "    if \"mlp_out\" in cache_name:\n",
    "        output[:, pos_indexer, :] = patching_cache[cache_name][:, pos_indexer, :]\n",
    "        return output\n",
    "    \n",
    "    # Hook point should be `resid_post_i` or `attn_out_i`, respectively\n",
    "    elif \"resid_post\" in cache_name or \"attn_out\" in cache_name:\n",
    "        new_output = [o for o in output]\n",
    "        new_output[0][:, pos_indexer, :] = patching_cache[cache_name][:, pos_indexer, :]\n",
    "        return tuple(new_output)\n",
    "    \n",
    "    # Hook point should be `attn_out_i`\n",
    "    elif \"head_out\" in cache_name:\n",
    "        if original_cache is None:\n",
    "            raise ValueError(\"original_cache must be provided\")\n",
    "        if head_indexer is None:\n",
    "            raise ValueError(\"head_indexer must be provided\")\n",
    "        new_activation = original_cache[cache_name].clone()\n",
    "        new_activation[:, pos_indexer, head_indexer, :] = patching_cache[cache_name][:, pos_indexer, head_indexer, :]\n",
    "        new_output = [o for o in output]\n",
    "        new_output[0] = new_activation.sum(dim=2)\n",
    "        return tuple(new_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test patching resid_post, dishonest -> honest, should have high? recovery\n",
    "# CONFUSION: is the cached resid_post_15 before or after injection?\n",
    "model.reset_hooks()\n",
    "patch_hook_fnc = partial(\n",
    "    patch_hook,\n",
    "    patching_cache=dishonest_cache,\n",
    "    cache_name=\"resid_post_15\",\n",
    ")\n",
    "model.add_hook(\"resid_post_15\", patch_hook_fnc)\n",
    "\n",
    "# Honest run\n",
    "patched_logits = model(PROMPTS)\n",
    "skld_recovery(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test patching resid_post, dishonest -> honest, should have high recovery\n",
    "model.reset_hooks()\n",
    "patch_hook_fnc = partial(\n",
    "    patch_hook,\n",
    "    patching_cache=dishonest_cache,\n",
    "    cache_name=\"resid_post_16\",\n",
    ")\n",
    "model.add_hook(\"resid_post_16\", patch_hook_fnc)\n",
    "\n",
    "# Honest run\n",
    "patched_logits = model(PROMPTS)\n",
    "skld_recovery(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test patching resid_post, honest -> dishonest, should have low? recovery\n",
    "model.reset_hooks()\n",
    "patch_hook_fnc = partial(\n",
    "    patch_hook,\n",
    "    patching_cache=honest_cache,\n",
    "    cache_name=\"resid_post_15\",\n",
    ")\n",
    "model.add_hook(\"resid_post_15\", patch_hook_fnc)\n",
    "\n",
    "# Dishonest run\n",
    "make_dishonest(model)\n",
    "patched_logits = model(PROMPTS)\n",
    "skld_recovery(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test patching resid_post, honest -> dishonest, should have low? recovery\n",
    "model.reset_hooks()\n",
    "patch_hook_fnc = partial(\n",
    "    patch_hook,\n",
    "    patching_cache=honest_cache,\n",
    "    cache_name=\"resid_post_16\",\n",
    ")\n",
    "model.add_hook(\"resid_post_16\", patch_hook_fnc)\n",
    "\n",
    "# Dishonest run\n",
    "make_dishonest(model)\n",
    "patched_logits = model(PROMPTS)\n",
    "skld_recovery(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
