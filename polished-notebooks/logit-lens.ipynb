{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy snippet to get repo root from anywhere in the repo\n",
    "import sys\n",
    "from subprocess import check_output\n",
    "ROOT = check_output('git rev-parse --show-toplevel', shell=True).decode(\"utf-8\").strip()\n",
    "if ROOT not in sys.path: sys.path.append(ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import einops\n",
    "\n",
    "from functools import partial\n",
    "from dishonesty.mistral_lens import load_model\n",
    "from dishonesty.prompts import PROMPTS\n",
    "from dishonesty.utils import ntensor_to_long\n",
    "\n",
    "\n",
    "t.set_grad_enabled(False)\n",
    "device = t.device('cuda:0' if t.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25923dce62864a84af1bd62acf391717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4096])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directions = t.load(f\"{ROOT}/directions/honesty_mistral-instruct-v0.1.pt\").to(device)\n",
    "directions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define injection hook\n",
    "def inject(module, input, output, alpha=-8.25):\n",
    "    new_output = [o for o in output]\n",
    "    new_output[0] += alpha * directions[15]\n",
    "    return tuple(new_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Logit Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define activations to cache\n",
    "cache_names = [\"embed_tokens\", \"final_rscale\"]\n",
    "cache_names += [\"resid_post_13\", \"resid_post_14\", \"resid_post_15\", \"resid_post_16\", \"resid_post_17\", \"resid_post_31\", \"final_norm_out\"]\n",
    "for i in range(32):\n",
    "    cache_names.append(f\"attn_out_{i}\")\n",
    "    cache_names.append(f\"mlp_out_{i}\")\n",
    "\n",
    "# Run with cache for all alphas\n",
    "caches = []\n",
    "alphas = np.linspace(-8.25, 0, 12)\n",
    "for alpha in alphas:\n",
    "    model.reset_hooks()\n",
    "    model.add_hook(f\"resid_post_15\", partial(inject, alpha=alpha))\n",
    "    _, cache = model.run_with_cache(PROMPTS, cache_names, pos_slicer=-1)\n",
    "    caches.append(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect activations needed for logit lens\n",
    "decomp_resids = []\n",
    "final_rscales = []\n",
    "\n",
    "for cache in caches:\n",
    "    # Collect decomposed resids\n",
    "    resid, labels = cache.get_decomposed_resid_stack(return_labels=True)  # [comp, batch, d_model]\n",
    "    decomp_resids.append(resid)\n",
    "    # Collect final rscales\n",
    "    final_rscale = cache[\"final_rscale\"][None, :, :]  # [1, batch, 1], keep only final pos\n",
    "    final_rscales.append(final_rscale)\n",
    "\n",
    "# Unify tensors\n",
    "decomp_resids = t.stack(decomp_resids, dim=0)  # [alpha, comp, batch, d_model]\n",
    "final_rscales = t.stack(final_rscales, dim=0)  # [alpha, 1, batch, 1]\n",
    "\n",
    "assert decomp_resids.dim() == 4\n",
    "assert final_rscales.dim() == 4\n",
    "\n",
    "# Add the direction injection to the decomposed resid stack\n",
    "resid_labels = labels[:3+15*2] + [\"--> INJECTION\"] + labels[3+15*2:]\n",
    "\n",
    "injections = [alpha * directions[15].to(t.float16) for alpha in alphas]\n",
    "injections = t.stack(injections, dim=0)[:, None, None, :]\n",
    "injections = einops.repeat(\n",
    "    injections,\n",
    "    \"alpha 1 1 d_model -> alpha 1 batch d_model\",\n",
    "    batch=decomp_resids.shape[2],\n",
    ")\n",
    "\n",
    "# Place the injection where resid_post_15 would be\n",
    "decomp_resids = t.cat([\n",
    "    decomp_resids[:, :3+15*2],\n",
    "    injections,\n",
    "    decomp_resids[:, 3+15*2:],\n",
    "], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 66, 20, 4096])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomp_resids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -8.25 True\n",
      "1 -7.5 True\n",
      "2 -6.75 True\n",
      "3 -6.0 True\n",
      "4 -5.25 True\n",
      "5 -4.5 True\n",
      "6 -3.75 True\n",
      "7 -3.0 True\n",
      "8 -2.25 True\n",
      "9 -1.5 True\n",
      "10 -0.75 True\n",
      "11 0.0 True\n"
     ]
    }
   ],
   "source": [
    "# Sanity check that the decomposition + injection is equal to the final resid_post\n",
    "for i, alpha in enumerate(alphas):\n",
    "    match = t.allclose(\n",
    "        decomp_resids[i].sum(dim=0),\n",
    "        caches[i][\"resid_post_31\"],\n",
    "        atol=1e-2,\n",
    "        rtol=1e-3,\n",
    "    )\n",
    "    print(i, alpha, match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rms_norm(resid, rscale, weight):\n",
    "    input_dtype = resid.dtype\n",
    "    scaled_resid = rscale * resid.to(rscale.dtype) * weight.to(rscale.dtype)\n",
    "    return scaled_resid.to(input_dtype)\n",
    "\n",
    "# Apply final rms norm to decompsed resids\n",
    "scaled_decomp_resids = apply_rms_norm(\n",
    "    decomp_resids,\n",
    "    final_rscales,\n",
    "    model.hf_model.model.norm.weight,\n",
    ")  # [alpha, comp, batch, d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dishonest tokens\n",
    "model.reset_hooks()\n",
    "model.add_hook(f\"resid_post_15\", partial(inject, alpha=-8.25))\n",
    "dishonest_logits = model(PROMPTS)[:, -1]  # [batch, d_vocab]\n",
    "dishonest_tokens = dishonest_logits.argmax(dim=-1)  # [batch]\n",
    "\n",
    "# Get honest tokens\n",
    "model.reset_hooks()\n",
    "honest_logits = model(PROMPTS)[:, -1]  # [batch, d_vocab]\n",
    "honest_tokens = honest_logits.argmax(dim=-1)  # [batch]\n",
    "\n",
    "# Calculate \"original\" logit diffs\n",
    "original_logit_diffs = (\n",
    "    dishonest_logits.gather(dim=-1, index=dishonest_tokens[:, None]).squeeze(-1)\n",
    "    - dishonest_logits.gather(dim=-1, index=honest_tokens[:, None]).squeeze(-1)\n",
    ")  # [batch]\n",
    "\n",
    "# Get logit diff directions\n",
    "W_U = model.hf_model.lm_head.weight  # [d_vocab, d_model]\n",
    "logit_diff_directions = W_U[dishonest_tokens] - W_U[honest_tokens]  # [batch, d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate logit diffs\n",
    "logit_diffs_decomp = einops.einsum(\n",
    "    scaled_decomp_resids,\n",
    "    logit_diff_directions,\n",
    "    \"alpha comp batch d_model, batch d_model -> alpha comp batch\",\n",
    ")\n",
    "\n",
    "# Sanity check that the sum of the decomposed logit diffs is approx. equal to\n",
    "# the original logit diffs for alpha = -8.25\n",
    "t.allclose(\n",
    "    logit_diffs_decomp[0].to(t.float32).sum(dim=0),\n",
    "    original_logit_diffs,\n",
    "    atol=1e-2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4453, 3.1250, 1.5312, 2.3125, 1.5449, 2.1484, 0.6255, 4.0078, 2.4219,\n",
       "        2.6484, 1.8779, 2.2480, 3.0664, 2.6387, 0.0000, 0.8672, 0.5234, 2.3008,\n",
       "        0.1597, 0.7588], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diffs_accum = logit_diffs_decomp.cumsum(dim=1)  # [alpha, comp, batch]\n",
    "logit_diffs_accum[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4453, 3.1250, 1.5312, 2.3125, 1.5547, 2.1484, 0.6250, 4.0078, 2.4141,\n",
       "        2.6484, 1.8828, 2.2422, 3.0625, 2.6484, 0.0000, 0.8672, 0.5234, 2.2969,\n",
       "        0.1562, 0.7578], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_logit_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to long format\n",
    "df_decomp = ntensor_to_long(\n",
    "    logit_diffs_decomp,\n",
    "    value_name=\"Logit Diff Contribution\",\n",
    "    dim_names=[\"Alpha\", \"Component\", \"Batch\"],\n",
    ")\n",
    "df_accum = ntensor_to_long(\n",
    "    logit_diffs_accum,\n",
    "    value_name=\"Logit Diff\",\n",
    "    dim_names=[\"Alpha\", \"Component\", \"Batch\"],\n",
    ")\n",
    "\n",
    "# Map integer index to the alpha value\n",
    "alpha_map = {i: alpha for i, alpha in enumerate(alphas)}\n",
    "df_decomp[\"Alpha\"] = df_decomp[\"Alpha\"].map(alpha_map)\n",
    "df_accum[\"Alpha\"] = df_accum[\"Alpha\"].map(alpha_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = df_decomp[\"Logit Diff Contribution\"].abs().max()\n",
    "\n",
    "fig = px.line(\n",
    "    df_decomp,\n",
    "    x=\"Component\",\n",
    "    y=\"Logit Diff Contribution\",\n",
    "    color=\"Alpha\",\n",
    "    animation_frame=\"Batch\",\n",
    "    title=\"Logit Lens (Decomposed Residual Stream): dishonest_logits[dishonest_token] - dishonest_logits[honest_token]\",\n",
    ")\n",
    "\n",
    "# Set plot titles and axis labels\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=0.1,\n",
    "        gridcolor='lightgray',\n",
    "        dtick=1,\n",
    "        showline=True,\n",
    "        linecolor='grey',\n",
    "        zeroline=True,\n",
    "        zerolinewidth=1,\n",
    "        zerolinecolor='black',\n",
    "        linewidth=1,\n",
    "        tickmode='array',  # Use an array for tick values\n",
    "        tickvals=list(range(len(resid_labels))),  # Set tick positions\n",
    "        ticktext=resid_labels,\n",
    "        tickangle=-90,\n",
    "    ),\n",
    "    \n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=0.1,\n",
    "        gridcolor='lightgray',\n",
    "        dtick=1,\n",
    "        showline=True,\n",
    "        zeroline=True,\n",
    "        zerolinewidth=2,\n",
    "        zerolinecolor='black',\n",
    "        linewidth=1,\n",
    "        linecolor='grey',\n",
    "        tickmode='array',\n",
    "        tick0=0,\n",
    "        range=[-ylim, ylim],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Set background color to white\n",
    "fig.update_layout(plot_bgcolor='white')\n",
    "\n",
    "# Show the legend\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "\n",
    "# Fix margins for visibility\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=100, b=20))\n",
    "fig['layout']['updatemenus'][0]['pad']=dict(r= 20, t= 110, b=0)\n",
    "fig['layout']['sliders'][0]['pad']=dict(r= 10, t= 100,)\n",
    "\n",
    "# Create red-green color gradient for alpha\n",
    "plotly_colors = []\n",
    "for redness in np.linspace(255, 0, 12):\n",
    "    greenness = 255 - redness\n",
    "    plotly_colors.append(f\"rgb({redness}, {greenness}, 0)\")\n",
    "\n",
    "# Change colors for first frame\n",
    "for i, color in zip(range(len(alphas)), plotly_colors):\n",
    "    fig.data[i].line.color = color\n",
    "\n",
    "# Change colors for all frames\n",
    "for frame in fig.frames:\n",
    "    for i, color in zip(range(len(alphas)), plotly_colors):\n",
    "        frame.data[i].line.color = color\n",
    "\n",
    "fig_decomp = fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = df_accum[\"Logit Diff\"].abs().max()\n",
    "\n",
    "fig = px.line(\n",
    "    df_accum,\n",
    "    x=\"Component\",\n",
    "    y=\"Logit Diff\",\n",
    "    color=\"Alpha\",\n",
    "    animation_frame=\"Batch\",\n",
    "    title=\"Logit Lens (Accumulated Residual Stream): dishonest_logits[dishonest_token] - dishonest_logits[honest_token]\",\n",
    ")\n",
    "\n",
    "# Set plot titles and axis labels\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=0.1,\n",
    "        gridcolor='lightgray',\n",
    "        dtick=1,\n",
    "        showline=True,\n",
    "        linecolor='grey',\n",
    "        zeroline=True,\n",
    "        zerolinewidth=1,\n",
    "        zerolinecolor='black',\n",
    "        linewidth=1,\n",
    "        tickmode='array',  # Use an array for tick values\n",
    "        tickvals=list(range(len(resid_labels))),  # Set tick positions\n",
    "        ticktext=resid_labels,\n",
    "        tickangle=-90,\n",
    "    ),\n",
    "    \n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=0.1,\n",
    "        gridcolor='lightgray',\n",
    "        dtick=1,\n",
    "        showline=True,\n",
    "        zeroline=True,\n",
    "        zerolinewidth=2,\n",
    "        zerolinecolor='black',\n",
    "        linewidth=1,\n",
    "        linecolor='grey',\n",
    "        tickmode='array',\n",
    "        tick0=0,\n",
    "        range=[-ylim, ylim],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Set background color to white\n",
    "fig.update_layout(plot_bgcolor='white')\n",
    "\n",
    "# Show the legend\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "\n",
    "# Fix margins for visibility\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=100, b=20))\n",
    "fig['layout']['updatemenus'][0]['pad']=dict(r= 20, t= 110, b=0)\n",
    "fig['layout']['sliders'][0]['pad']=dict(r= 10, t= 100,)\n",
    "\n",
    "# Create red-green color gradient for alpha\n",
    "plotly_colors = []\n",
    "for redness in np.linspace(255, 0, 12):\n",
    "    greenness = 255 - redness\n",
    "    plotly_colors.append(f\"rgb({redness}, {greenness}, 0)\")\n",
    "\n",
    "# Change colors for first frame\n",
    "for i, color in zip(range(len(alphas)), plotly_colors):\n",
    "    fig.data[i].line.color = color\n",
    "\n",
    "# Change colors for all frames\n",
    "for frame in fig.frames:\n",
    "    for i, color in zip(range(len(alphas)), plotly_colors):\n",
    "        frame.data[i].line.color = color\n",
    "\n",
    "fig_accum = fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_decomp.show()\n",
    "# fig_accum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_decomp.write_html(f\"{ROOT}/figs/logit-lens-decomp.html\")\n",
    "fig_accum.write_html(f\"{ROOT}/figs/logit-lens-accum.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
